import os
import re
import pandas as pd
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, util

# --- 1ï¸âƒ£ ê²½ë¡œ ì„¤ì • ---
base_dir = "bills_txt"
output_csv = "bill_exceptions_summary.csv"

# --- 2ï¸âƒ£ ëª¨ë¸ ë¡œë“œ (KoSBERT ê¸°ë°˜ í•œêµ­ì–´ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸) ---
print("ğŸ”„ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# ì˜ˆì™¸ ë¬¸ì¥ ì˜ë¯¸ ê¸°ì¤€ ë²¡í„°
example_sentences = [
    "ë‹¤ë§Œ ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤.",
    "ê·¸ëŸ¬ë‚˜ íŠ¹ë³„í•œ ì‚¬ì •ì´ ìˆëŠ” ë•Œì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤.",
    "ì˜ˆì™¸ì ìœ¼ë¡œ ëŒ€í†µë ¹ë ¹ìœ¼ë¡œ ì •í•˜ëŠ” ê²½ìš°ì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤.",
    "ë‹¤ë§Œ ì œ2í•­ì˜ ê²½ìš°ì—ëŠ” ì´ë¥¼ ì ìš©í•˜ì§€ ì•„ë‹ˆí•œë‹¤."
]
example_embeddings = model.encode(example_sentences, convert_to_tensor=True)

# --- 3ï¸âƒ£ ì˜ˆì™¸ ë¬¸ì¥ íƒì§€ í•¨ìˆ˜ ---
def extract_exceptions_from_text(text, threshold=0.45):
    # ì˜¨ì ìœ¼ë¡œ ëë‚˜ëŠ” ë¬¸ì¥ë§Œ ì¶”ì¶œ
    sentences = [s.strip() for s in re.findall(r"[^.]+?\.", text)]
    sentences = [s for s in sentences if len(s) > 5]  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œì™¸

    # 1ì°¨ í•„í„°: í‚¤ì›Œë“œ í¬í•¨ ë¬¸ì¥ë§Œ
    keywords = ["ë‹¤ë§Œ", "ê·¸ëŸ¬ë‚˜", "ì˜ˆì™¸", "ì œì™¸", "ë¶ˆêµ¬í•˜ê³ "]
    candidates = [
        s for s in sentences
        if any(k in s for k in keywords) and s.endswith(".")
    ]

    results = []
    for s in candidates:
        emb = model.encode(s, convert_to_tensor=True)
        sim = util.cos_sim(emb, example_embeddings).max().item()
        if sim > threshold:
            results.append((s, round(sim, 3)))
    return results

# --- 4ï¸âƒ£ bills_txt í´ë” ë‚´ ëª¨ë“  txt ì²˜ë¦¬ ---
records = []
files = [f for f in os.listdir(base_dir) if f.endswith(".txt")]

print(f"ğŸ“‚ ì´ {len(files)}ê°œ ë²•ì•ˆ ì²˜ë¦¬ ì¤‘...\n")

for fname in tqdm(files, desc="Processing bills"):
    try:
        # bill_id ì¶”ì¶œ (íŒŒì¼ëª… í˜•íƒœ: [2000010] ë²•ì•ˆì œëª©.txt)
        m = re.match(r"\[(\d+)\]", fname)
        bill_id = m.group(1) if m else os.path.splitext(fname)[0]

        with open(os.path.join(base_dir, fname), "r", encoding="utf-8") as f:
            text = f.read()

        exceptions = extract_exceptions_from_text(text)
        count = len(exceptions)
        avg_sim = round(sum(sim for _, sim in exceptions) / count, 3) if count > 0 else 0.0
        examples = " | ".join([s for s, _ in exceptions[:3]])  # ëŒ€í‘œ ë¬¸ì¥ 3ê°œë§Œ ì €ì¥

        records.append({
            "bill_id": bill_id,
            "filename": fname,
            "exception_count": count,
            "avg_similarity": avg_sim,
            "examples": examples
        })
    except Exception as e:
        print(f"[ERROR] {fname}: {e}")

# --- 5ï¸âƒ£ ê²°ê³¼ ì €ì¥ ---
df = pd.DataFrame(records)
df.to_csv(output_csv, index=False, encoding="utf-8-sig")

print(f"\nâœ… ì™„ë£Œ! ì´ {len(df)}ê±´ì˜ ë²•ì•ˆ ê²°ê³¼ ì €ì¥ë¨.")
print(f"ê²°ê³¼ íŒŒì¼: {output_csv}")
